{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_171526\n",
      "Epoch 00123: early stopping\n",
      "215/215 [==============================] - 0s 666us/step\n",
      "[0.         0.85302854 0.85289939 0.85277024 0.8526411  0.8526411\n",
      " 0.8526411  0.8526411  0.8526411  0.8526411  0.8526411  0.85257652\n",
      " 0.8526411 ]\n",
      "1\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_171539\n",
      "Epoch 00092: early stopping\n",
      "215/215 [==============================] - 0s 625us/step\n",
      "[0.         0.79068615 0.7905623  0.7905623  0.7905623  0.7905623\n",
      " 0.7905623  0.7905623  0.7905623  0.7905623  0.7905623  0.7905623\n",
      " 0.7905623 ]\n",
      "2\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_171549\n",
      "Epoch 00072: early stopping\n",
      "215/215 [==============================] - 0s 438us/step\n",
      "[0.         0.83547908 0.83560287 0.83547908 0.83535529 0.83547908\n",
      " 0.83547908 0.83560287 0.83560287 0.83560287 0.83560287 0.83560287\n",
      " 0.83566477]\n",
      "3\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_171557\n",
      "Epoch 00094: early stopping\n",
      "215/215 [==============================] - 0s 893us/step\n",
      "[0.         0.85558781 0.85546686 0.85546686 0.85546686 0.85534591\n",
      " 0.85534591 0.85522496 0.85522496 0.85522496 0.85522496 0.85522496\n",
      " 0.85522496]\n",
      "4\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_171609\n",
      "Epoch 00074: early stopping\n",
      "215/215 [==============================] - 0s 882us/step\n",
      "[0.         0.82402581 0.82390171 0.82390171 0.82390171 0.82390171\n",
      " 0.82390171 0.82390171 0.82390171 0.82390171 0.82390171 0.82390171\n",
      " 0.82390171]\n",
      "5\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_171618\n",
      "Epoch 00096: early stopping\n",
      "215/215 [==============================] - 0s 922us/step\n",
      "[0.         0.79313263 0.79313263 0.79313263 0.79313263 0.79313263\n",
      " 0.79313263 0.79313263 0.79313263 0.79313263 0.79313263 0.79313263\n",
      " 0.79313263]\n",
      "6\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_171630\n",
      "Epoch 00117: early stopping\n",
      "215/215 [==============================] - 0s 1ms/step\n",
      "[0.         0.81908324 0.81938012 0.81938012 0.81938012 0.81938012\n",
      " 0.81938012 0.81938012 0.81932075 0.81878637 0.81926137 0.81979575\n",
      " 0.81979575]\n",
      "7\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_171642\n",
      "Epoch 00094: early stopping\n",
      "215/215 [==============================] - 0s 917us/step\n",
      "[0.         0.81985906 0.81998719 0.81998719 0.81998719 0.81985906\n",
      " 0.81985906 0.81985906 0.81985906 0.81985906 0.81985906 0.81985906\n",
      " 0.81985906]\n",
      "8\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_171653\n",
      "Epoch 00080: early stopping\n",
      "215/215 [==============================] - 0s 669us/step\n",
      "[0.         0.79355894 0.79368474 0.79355894 0.79355894 0.79368474\n",
      " 0.79381054 0.79381054 0.79381054 0.79381054 0.79381054 0.79381054\n",
      " 0.79381054]\n",
      "9\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_171703\n",
      "Epoch 00109: early stopping\n",
      "215/215 [==============================] - 0s 600us/step\n",
      "[0.         0.78641591 0.78641591 0.78641591 0.78641591 0.78641591\n",
      " 0.78635601 0.78641591 0.78635601 0.78635601 0.78635601 0.7864758\n",
      " 0.78659559]\n",
      "10\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_171714\n",
      "Epoch 00102: early stopping\n",
      "215/215 [==============================] - 0s 650us/step\n",
      "[0.         0.79813971 0.79807811 0.79820131 0.79820131 0.79820131\n",
      " 0.79820131 0.79820131 0.79820131 0.79820131 0.79820131 0.79820131\n",
      " 0.79820131]\n",
      "11\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_171725\n",
      "Epoch 00083: early stopping\n",
      "215/215 [==============================] - 0s 510us/step\n",
      "[0.         0.84358524 0.84335091 0.84323374 0.84323374 0.84323374\n",
      " 0.84323374 0.84323374 0.84323374 0.84323374 0.84323374 0.84323374\n",
      " 0.84323374]\n",
      "12\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_171734\n",
      "Epoch 00089: early stopping\n",
      "215/215 [==============================] - 0s 912us/step\n",
      "[0.         0.80996036 0.81020813 0.81020813 0.81020813 0.81020813\n",
      " 0.81020813 0.81020813 0.81020813 0.81020813 0.81027007 0.81027007\n",
      " 0.81027007]\n",
      "13\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_171746\n",
      "Epoch 00111: early stopping\n",
      "215/215 [==============================] - 0s 905us/step\n",
      "[0.         0.782587   0.7823999  0.78215043 0.78171386 0.78158912\n",
      " 0.78158912 0.78121492 0.78115255 0.78127729 0.78127729 0.78121492\n",
      " 0.78115255]\n",
      "14\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_171759\n",
      "Epoch 00095: early stopping\n",
      "215/215 [==============================] - 0s 899us/step\n",
      "[0.         0.77443704 0.77431123 0.77431123 0.77443704 0.77443704\n",
      " 0.77443704 0.77443704 0.77443704 0.77443704 0.77437414 0.77449994\n",
      " 0.77456284]\n",
      "15\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_171810\n",
      "Epoch 00107: early stopping\n",
      "215/215 [==============================] - 0s 956us/step\n",
      "[0.         0.72791921 0.72806144 0.72806144 0.72806144 0.72806144\n",
      " 0.72806144 0.72806144 0.72806144 0.72806144 0.72806144 0.72806144\n",
      " 0.72799033]\n",
      "16\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_171822\n",
      "Epoch 00074: early stopping\n",
      "215/215 [==============================] - 0s 850us/step\n",
      "[0.        0.8152748 0.8152748 0.8152748 0.8152748 0.8152748 0.8152748\n",
      " 0.8152748 0.8152748 0.8152748 0.8152748 0.8152748 0.8152748]\n",
      "17\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_171831\n",
      "Epoch 00102: early stopping\n",
      "215/215 [==============================] - 0s 697us/step\n",
      "[0.         0.82448651 0.82417718 0.82417718 0.82417718 0.82417718\n",
      " 0.82417718 0.82417718 0.82423905 0.82423905 0.82417718 0.82430092\n",
      " 0.82430092]\n",
      "18\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_171842\n",
      "Epoch 00100: early stopping\n",
      "215/215 [==============================] - 0s 594us/step\n",
      "[0.         0.79974539 0.8        0.79993635 0.8        0.8\n",
      " 0.8        0.8        0.8        0.79987269 0.79993635 0.79993635\n",
      " 0.79987269]\n",
      "19\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_171853\n",
      "Epoch 00085: early stopping\n",
      "215/215 [==============================] - 0s 607us/step\n",
      "[0.         0.80389993 0.80402257 0.80402257 0.80402257 0.80402257\n",
      " 0.80402257 0.80402257 0.80402257 0.80402257 0.80402257 0.80402257\n",
      " 0.80402257]\n",
      "20\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_171902\n",
      "Epoch 00112: early stopping\n",
      "215/215 [==============================] - 0s 472us/step\n",
      "[0.         0.75712875 0.75737563 0.75731391 0.75737563 0.75737563\n",
      " 0.75737563 0.75731391 0.75731391 0.75774596 0.75774596 0.75774596\n",
      " 0.7566967 ]\n",
      "21\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_171914\n",
      "Epoch 00116: early stopping\n",
      "215/215 [==============================] - 0s 910us/step\n",
      "[0.         0.84501678 0.84527498 0.84475859 0.84508133 0.84462949\n",
      " 0.84521043 0.84437129 0.84579138 0.84566228 0.84566228 0.84592048\n",
      " 0.84592048]\n",
      "22\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_171928\n",
      "Epoch 00100: early stopping\n",
      "215/215 [==============================] - 0s 945us/step\n",
      "[0.         0.82647631 0.82647631 0.82647631 0.82647631 0.82647631\n",
      " 0.82647631 0.82647631 0.82647631 0.82647631 0.82647631 0.82647631\n",
      " 0.82647631]\n",
      "23\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_171939\n",
      "Epoch 00096: early stopping\n",
      "215/215 [==============================] - 0s 919us/step\n",
      "[0.         0.83047349 0.83047349 0.83047349 0.83047349 0.83047349\n",
      " 0.83047349 0.83047349 0.83047349 0.83047349 0.83047349 0.83047349\n",
      " 0.83047349]\n",
      "24\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_171951\n",
      "Epoch 00089: early stopping\n",
      "215/215 [==============================] - 0s 923us/step\n",
      "[0.         0.75572014 0.75572014 0.75572014 0.75572014 0.75572014\n",
      " 0.75572014 0.75572014 0.75572014 0.75572014 0.75572014 0.75572014\n",
      " 0.75578627]\n",
      "25\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172001\n",
      "Epoch 00118: early stopping\n",
      "215/215 [==============================] - 0s 880us/step\n",
      "[0.         0.81593903 0.81593903 0.81593903 0.81593903 0.81593903\n",
      " 0.81593903 0.81593903 0.81593903 0.81593903 0.81593903 0.81593903\n",
      " 0.81593903]\n",
      "26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172014\n",
      "Epoch 00094: early stopping\n",
      "215/215 [==============================] - 0s 668us/step\n",
      "[0.         0.78684303 0.78672597 0.7861407  0.7861407  0.7861407\n",
      " 0.7861407  0.7861407  0.78590659 0.78590659 0.78578954 0.78578954\n",
      " 0.78596512]\n",
      "27\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172024\n",
      "Epoch 00122: early stopping\n",
      "215/215 [==============================] - 0s 625us/step\n",
      "[0.         0.76833233 0.76833233 0.76833233 0.76833233 0.76833233\n",
      " 0.76833233 0.76833233 0.76833233 0.76833233 0.76833233 0.76833233\n",
      " 0.76827213]\n",
      "28\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172037\n",
      "Epoch 00076: early stopping\n",
      "215/215 [==============================] - 0s 576us/step\n",
      "[0.         0.79159116 0.79159116 0.79171197 0.79171197 0.79171197\n",
      " 0.79171197 0.79171197 0.79171197 0.79171197 0.79171197 0.79171197\n",
      " 0.79171197]\n",
      "29\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172046\n",
      "Epoch 00085: early stopping\n",
      "215/215 [==============================] - 0s 481us/step\n",
      "[0.         0.84629981 0.84629981 0.84629981 0.84629981 0.84629981\n",
      " 0.84629981 0.84629981 0.84629981 0.84629981 0.84629981 0.84629981\n",
      " 0.84636306]\n",
      "30\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172055\n",
      "Epoch 00091: early stopping\n",
      "215/215 [==============================] - 0s 390us/step\n",
      "[0.         0.80597575 0.80597575 0.80597575 0.80610076 0.80610076\n",
      " 0.80610076 0.80610076 0.80610076 0.80610076 0.80610076 0.80610076\n",
      " 0.80610076]\n",
      "31\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172105\n",
      "Epoch 00119: early stopping\n",
      "215/215 [==============================] - 0s 907us/step\n",
      "[0.         0.76256467 0.76287263 0.76287263 0.76428923 0.76348854\n",
      " 0.76256467 0.76428923 0.76256467 0.76256467 0.76256467 0.76256467\n",
      " 0.76256467]\n",
      "32\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172120\n",
      "Epoch 00087: early stopping\n",
      "215/215 [==============================] - 0s 929us/step\n",
      "[0.         0.82755643 0.82743308 0.82743308 0.82743308 0.82743308\n",
      " 0.82743308 0.82743308 0.82743308 0.82743308 0.82743308 0.82743308\n",
      " 0.82743308]\n",
      "33\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172130\n",
      "Epoch 00107: early stopping\n",
      "215/215 [==============================] - 0s 935us/step\n",
      "[0.         0.79240989 0.79234838 0.79222537 0.79216386 0.79222537\n",
      " 0.79228687 0.79222537 0.79222537 0.79234838 0.79234838 0.79234838\n",
      " 0.79222537]\n",
      "34\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172142\n",
      "Epoch 00122: early stopping\n",
      "215/215 [==============================] - 0s 927us/step\n",
      "[0.         0.76510348 0.76522311 0.76522311 0.76510348 0.76528293\n",
      " 0.76498385 0.76474459 0.76474459 0.76450532 0.76432588 0.76414643\n",
      " 0.76486422]\n",
      "35\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172155\n",
      "Epoch 00067: early stopping\n",
      "215/215 [==============================] - 0s 808us/step\n",
      "[0.         0.81849099 0.81849099 0.81861695 0.81861695 0.81861695\n",
      " 0.81861695 0.81861695 0.81861695 0.81861695 0.81861695 0.81874291\n",
      " 0.81874291]\n",
      "36\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172204\n",
      "Epoch 00095: early stopping\n",
      "215/215 [==============================] - 0s 646us/step\n",
      "[0.         0.83044125 0.83019336 0.83019336 0.83019336 0.83019336\n",
      " 0.83019336 0.83019336 0.83019336 0.83019336 0.83019336 0.83019336\n",
      " 0.83019336]\n",
      "37\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172214\n",
      "Epoch 00123: early stopping\n",
      "215/215 [==============================] - 0s 606us/step\n",
      "[0.         0.81486793 0.81486793 0.81486793 0.81486793 0.81486793\n",
      " 0.81486793 0.81486793 0.81486793 0.81486793 0.81486793 0.81480817\n",
      " 0.81480817]\n",
      "38\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172227\n",
      "Epoch 00091: early stopping\n",
      "215/215 [==============================] - 0s 677us/step\n",
      "[0.         0.76695284 0.76682842 0.76682842 0.76682842 0.76682842\n",
      " 0.76682842 0.76682842 0.76682842 0.76682842 0.76682842 0.76682842\n",
      " 0.76682842]\n",
      "39\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172237\n",
      "Epoch 00116: early stopping\n",
      "215/215 [==============================] - 0s 544us/step\n",
      "[0.         0.80405773 0.8041939  0.8041939  0.8041939  0.8041939\n",
      " 0.8041939  0.80412582 0.80405773 0.80392157 0.80412582 0.80392157\n",
      " 0.80324074]\n",
      "40\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172249\n",
      "Epoch 00074: early stopping\n",
      "215/215 [==============================] - 0s 869us/step\n",
      "[0.         0.83428646 0.83428646 0.8345464  0.83441643 0.83441643\n",
      " 0.83441643 0.83441643 0.83441643 0.8345464  0.8345464  0.8345464\n",
      " 0.8345464 ]\n",
      "41\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172300\n",
      "Epoch 00088: early stopping\n",
      "215/215 [==============================] - 0s 943us/step\n",
      "[0.       0.790119 0.790119 0.790119 0.790119 0.790119 0.790119 0.790119\n",
      " 0.790119 0.790119 0.790119 0.790119 0.790119]\n",
      "42\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172310\n",
      "Epoch 00128: early stopping\n",
      "215/215 [==============================] - 0s 928us/step\n",
      "[0.         0.83265085 0.83283151 0.83283151 0.83283151 0.83283151\n",
      " 0.83283151 0.83283151 0.83283151 0.83265085 0.83265085 0.83265085\n",
      " 0.83265085]\n",
      "43\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172324\n",
      "Epoch 00087: early stopping\n",
      "215/215 [==============================] - 0s 910us/step\n",
      "[0.         0.80838654 0.80838654 0.80844794 0.80838654 0.80844794\n",
      " 0.80838654 0.80844794 0.80844794 0.80838654 0.80838654 0.80838654\n",
      " 0.80838654]\n",
      "44\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172334\n",
      "Epoch 00102: early stopping\n",
      "215/215 [==============================] - 0s 842us/step\n",
      "[0.         0.79591589 0.79591589 0.79591589 0.79591589 0.79591589\n",
      " 0.79591589 0.79591589 0.79591589 0.79591589 0.79585511 0.79585511\n",
      " 0.79591589]\n",
      "45\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172346\n",
      "Epoch 00079: early stopping\n",
      "215/215 [==============================] - 0s 683us/step\n",
      "[0.         0.79101878 0.79101878 0.79101878 0.79101878 0.79101878\n",
      " 0.79101878 0.79101878 0.79101878 0.79101878 0.79101878 0.79101878\n",
      " 0.79101878]\n",
      "46\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172355\n",
      "Epoch 00114: early stopping\n",
      "215/215 [==============================] - 0s 634us/step\n",
      "[0.         0.82342943 0.82349742 0.82349742 0.82349742 0.82349742\n",
      " 0.82349742 0.82349742 0.82349742 0.82336144 0.82322546 0.82329345\n",
      " 0.8228855 ]\n",
      "47\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172407\n",
      "Epoch 00094: early stopping\n",
      "215/215 [==============================] - 0s 603us/step\n",
      "[0.         0.79166162 0.79190401 0.79166162 0.79166162 0.79166162\n",
      " 0.79166162 0.79154042 0.79154042 0.79154042 0.79154042 0.79154042\n",
      " 0.79154042]\n",
      "48\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172417\n",
      "Epoch 00073: early stopping\n",
      "215/215 [==============================] - 0s 507us/step\n",
      "[0.         0.82762161 0.82736491 0.82723655 0.82723655 0.8271082\n",
      " 0.8271082  0.8271082  0.82723655 0.82723655 0.82717238 0.8271082\n",
      " 0.8271082 ]\n",
      "49\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172425\n",
      "Epoch 00090: early stopping\n",
      "215/215 [==============================] - 0s 1ms/step\n",
      "[0.         0.80700202 0.80693883 0.80700202 0.80693883 0.80693883\n",
      " 0.80693883 0.80693883 0.80706522 0.80706522 0.80693883 0.80706522\n",
      " 0.80706522]\n",
      "50\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172438\n",
      "Epoch 00069: early stopping\n",
      "215/215 [==============================] - 0s 902us/step\n",
      "[0.         0.85551284 0.85551284 0.85551284 0.85551284 0.85563686\n",
      " 0.85563686 0.85563686 0.85563686 0.85563686 0.85563686 0.85563686\n",
      " 0.85563686]\n",
      "51\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172447\n",
      "Epoch 00095: early stopping\n",
      "215/215 [==============================] - 0s 957us/step\n",
      "[0.         0.7634787  0.76341586 0.76335302 0.76335302 0.76335302\n",
      " 0.76335302 0.76335302 0.76335302 0.7634787  0.7634787  0.76341586\n",
      " 0.76385572]\n",
      "52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172458\n",
      "Epoch 00094: early stopping\n",
      "215/215 [==============================] - 0s 902us/step\n",
      "[0.         0.78424702 0.78411618 0.78424702 0.78424702 0.78424702\n",
      " 0.78424702 0.78424702 0.78424702 0.78424702 0.78424702 0.7841816\n",
      " 0.78424702]\n",
      "53\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172509\n",
      "Epoch 00112: early stopping\n",
      "215/215 [==============================] - 0s 814us/step\n",
      "[0.         0.82860372 0.82860372 0.82860372 0.82860372 0.82860372\n",
      " 0.82860372 0.82860372 0.82860372 0.8286665  0.82854093 0.82847815\n",
      " 0.82841537]\n",
      "54\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172521\n",
      "Epoch 00083: early stopping\n",
      "215/215 [==============================] - 0s 668us/step\n",
      "[0.         0.77439935 0.77439935 0.77439935 0.77439935 0.77439935\n",
      " 0.77439935 0.77439935 0.77439935 0.77439935 0.77439935 0.77439935\n",
      " 0.77439935]\n",
      "55\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172531\n",
      "Epoch 00099: early stopping\n",
      "215/215 [==============================] - 0s 657us/step\n",
      "[0.         0.79799247 0.79761606 0.79761606 0.79761606 0.79761606\n",
      " 0.79761606 0.79761606 0.79761606 0.79761606 0.7976788  0.79780427\n",
      " 0.79780427]\n",
      "56\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172542\n",
      "Epoch 00102: early stopping\n",
      "215/215 [==============================] - 0s 626us/step\n",
      "[0.         0.81055631 0.81030851 0.81030851 0.81030851 0.81030851\n",
      " 0.81030851 0.81030851 0.81030851 0.81030851 0.81030851 0.81037046\n",
      " 0.81037046]\n",
      "57\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172553\n",
      "Epoch 00087: early stopping\n",
      "215/215 [==============================] - 0s 518us/step\n",
      "[0.         0.80577364 0.80601522 0.80601522 0.80601522 0.80601522\n",
      " 0.80601522 0.80589443 0.80589443 0.80589443 0.80589443 0.80589443\n",
      " 0.80589443]\n",
      "58\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172602\n",
      "Epoch 00074: early stopping\n",
      "215/215 [==============================] - 0s 917us/step\n",
      "[0.         0.75154004 0.75166838 0.75166838 0.75166838 0.75166838\n",
      " 0.75166838 0.75166838 0.75166838 0.75166838 0.75166838 0.75166838\n",
      " 0.75166838]\n",
      "59\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172613\n",
      "Epoch 00132: early stopping\n",
      "215/215 [==============================] - 0s 877us/step\n",
      "[0.         0.81689273 0.81689273 0.81689273 0.81689273 0.81689273\n",
      " 0.81695438 0.81707768 0.81720099 0.81683107 0.81707768 0.81381011\n",
      " 0.81300863]\n",
      "60\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172627\n",
      "Epoch 00096: early stopping\n",
      "215/215 [==============================] - 0s 921us/step\n",
      "[0.         0.79221261 0.79221261 0.792089   0.792089   0.792089\n",
      " 0.792089   0.792089   0.792089   0.792089   0.792089   0.792089\n",
      " 0.792089  ]\n",
      "61\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172638\n",
      "Epoch 00086: early stopping\n",
      "215/215 [==============================] - 0s 919us/step\n",
      "[0.         0.78514151 0.78525943 0.78537736 0.78537736 0.78537736\n",
      " 0.78537736 0.78537736 0.78537736 0.78537736 0.78537736 0.78537736\n",
      " 0.78537736]\n",
      "62\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172648\n",
      "Epoch 00087: early stopping\n",
      "215/215 [==============================] - 0s 913us/step\n",
      "[0.         0.77963839 0.77963839 0.77963839 0.77963839 0.77963839\n",
      " 0.77963839 0.77963839 0.77963839 0.77963839 0.77963839 0.77963839\n",
      " 0.77963839]\n",
      "63\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172658\n",
      "Epoch 00092: early stopping\n",
      "215/215 [==============================] - 0s 710us/step\n",
      "[0.         0.77737795 0.77761785 0.77761785 0.7774979  0.7774979\n",
      " 0.7774979  0.7774979  0.7774979  0.7774979  0.7774979  0.7774979\n",
      " 0.7774979 ]\n",
      "64\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172708\n",
      "Epoch 00101: early stopping\n",
      "215/215 [==============================] - 0s 639us/step\n",
      "[0.         0.78180255 0.78167976 0.78198674 0.78204813 0.78204813\n",
      " 0.78204813 0.78204813 0.78204813 0.78204813 0.78186395 0.78186395\n",
      " 0.78186395]\n",
      "65\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172719\n",
      "Epoch 00078: early stopping\n",
      "215/215 [==============================] - 0s 676us/step\n",
      "[0.         0.80563195 0.80545259 0.80533301 0.8053928  0.80521344\n",
      " 0.80527323 0.80521344 0.80521344 0.80521344 0.80509387 0.80521344\n",
      " 0.80527323]\n",
      "66\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172728\n",
      "Epoch 00078: early stopping\n",
      "215/215 [==============================] - 0s 443us/step\n",
      "[0.         0.82081586 0.82081586 0.82081586 0.82081586 0.82094294\n",
      " 0.82094294 0.82107002 0.82107002 0.82107002 0.82107002 0.82107002\n",
      " 0.82107002]\n",
      "67\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172737\n",
      "Epoch 00095: early stopping\n",
      "215/215 [==============================] - 0s 495us/step\n",
      "[0.         0.82801556 0.82801556 0.82801556 0.82801556 0.82801556\n",
      " 0.82801556 0.82801556 0.82801556 0.82801556 0.82795071 0.82795071\n",
      " 0.82795071]\n",
      "68\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172747\n",
      "Epoch 00091: early stopping\n",
      "215/215 [==============================] - 0s 902us/step\n",
      "[0.         0.80174404 0.80174404 0.80174404 0.80174404 0.80174404\n",
      " 0.80174404 0.80174404 0.80174404 0.80174404 0.80174404 0.80174404\n",
      " 0.80167992]\n",
      "69\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172800\n",
      "Epoch 00105: early stopping\n",
      "215/215 [==============================] - 0s 940us/step\n",
      "[0.         0.82437746 0.82437746 0.82437746 0.82450852 0.82450852\n",
      " 0.82450852 0.82450852 0.82450852 0.82450852 0.82450852 0.82450852\n",
      " 0.82450852]\n",
      "70\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172812\n",
      "Epoch 00090: early stopping\n",
      "215/215 [==============================] - 0s 948us/step\n",
      "[0.         0.83815357 0.83834302 0.83834302 0.83834302 0.83834302\n",
      " 0.83846931 0.83846931 0.83846931 0.83846931 0.83846931 0.83846931\n",
      " 0.83846931]\n",
      "71\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172822\n",
      "Epoch 00075: early stopping\n",
      "215/215 [==============================] - 0s 904us/step\n",
      "[0.         0.7420288  0.74209308 0.74222165 0.74222165 0.74222165\n",
      " 0.74222165 0.74222165 0.74222165 0.74222165 0.74222165 0.74222165\n",
      " 0.74222165]\n",
      "72\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172832\n",
      "Epoch 00098: early stopping\n",
      "215/215 [==============================] - 0s 792us/step\n",
      "[0.         0.78606038 0.78606038 0.78593614 0.78593614 0.78593614\n",
      " 0.78593614 0.78593614 0.78593614 0.78593614 0.78593614 0.78593614\n",
      " 0.78593614]\n",
      "73\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172843\n",
      "Epoch 00090: early stopping\n",
      "215/215 [==============================] - 0s 732us/step\n",
      "[0.         0.8475555  0.8481971  0.84806878 0.84794046 0.84794046\n",
      " 0.84794046 0.84806878 0.84806878 0.84806878 0.84806878 0.84806878\n",
      " 0.84806878]\n",
      "74\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172853\n",
      "Epoch 00103: early stopping\n",
      "215/215 [==============================] - 0s 614us/step\n",
      "[0.         0.82121662 0.8223912  0.82232938 0.8223912  0.82276212\n",
      " 0.82226756 0.82226756 0.8223912  0.82245302 0.82195846 0.82226756\n",
      " 0.82109298]\n",
      "75\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172904\n",
      "Epoch 00113: early stopping\n",
      "215/215 [==============================] - 0s 665us/step\n",
      "[0.         0.84436137 0.84436137 0.84436137 0.84436137 0.84436137\n",
      " 0.84436137 0.84436137 0.84436137 0.84436137 0.84436137 0.84436137\n",
      " 0.84436137]\n",
      "76\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172916\n",
      "Epoch 00081: early stopping\n",
      "215/215 [==============================] - 0s 529us/step\n",
      "[0.         0.81839143 0.81839143 0.81839143 0.81839143 0.81839143\n",
      " 0.81839143 0.81839143 0.81839143 0.81839143 0.81839143 0.81839143\n",
      " 0.81839143]\n",
      "77\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172925\n",
      "Epoch 00139: early stopping\n",
      "215/215 [==============================] - 0s 896us/step\n",
      "[0.         0.82107265 0.82107265 0.82107265 0.82107265 0.82107265\n",
      " 0.82100708 0.82113821 0.82113821 0.82107265 0.82074482 0.82231838\n",
      " 0.82290847]\n",
      "78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172941\n",
      "Epoch 00090: early stopping\n",
      "215/215 [==============================] - 0s 935us/step\n",
      "[0.         0.79872594 0.79845487 0.79845487 0.79845487 0.79845487\n",
      " 0.79845487 0.7985904  0.7985904  0.7985904  0.7985904  0.7985904\n",
      " 0.7985904 ]\n",
      "79\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_172952\n",
      "Epoch 00087: early stopping\n",
      "215/215 [==============================] - 0s 904us/step\n",
      "[0.         0.81752787 0.81764776 0.81764776 0.81764776 0.81764776\n",
      " 0.81764776 0.81752787 0.81764776 0.81764776 0.81764776 0.81764776\n",
      " 0.81764776]\n",
      "80\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_173002\n",
      "Epoch 00102: early stopping\n",
      "215/215 [==============================] - 0s 905us/step\n",
      "[0.         0.79054981 0.79073682 0.79073682 0.79073682 0.79073682\n",
      " 0.79073682 0.79073682 0.79073682 0.79073682 0.79067448 0.79061214\n",
      " 0.79092382]\n",
      "81\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_173014\n",
      "Epoch 00068: early stopping\n",
      "215/215 [==============================] - 0s 802us/step\n",
      "[0.         0.82194821 0.82182491 0.82182491 0.82182491 0.82182491\n",
      " 0.82182491 0.82182491 0.82182491 0.82182491 0.82182491 0.82182491\n",
      " 0.82182491]\n",
      "82\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_173023\n",
      "Epoch 00078: early stopping\n",
      "215/215 [==============================] - 0s 659us/step\n",
      "[0.         0.81277329 0.81290579 0.81303829 0.81303829 0.81303829\n",
      " 0.81303829 0.81303829 0.81303829 0.81303829 0.81303829 0.81290579\n",
      " 0.81290579]\n",
      "83\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_173032\n",
      "Epoch 00126: early stopping\n",
      "215/215 [==============================] - 0s 649us/step\n",
      "[0.         0.82153217 0.82146624 0.82146624 0.82146624 0.82146624\n",
      " 0.82146624 0.82146624 0.82140032 0.82146624 0.82133439 0.82146624\n",
      " 0.82140032]\n",
      "84\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_173045\n",
      "Epoch 00118: early stopping\n",
      "215/215 [==============================] - 0s 585us/step\n",
      "[0.         0.80223285 0.80235554 0.80235554 0.80235554 0.80235554\n",
      " 0.80235554 0.80235554 0.80235554 0.80235554 0.80235554 0.80235554\n",
      " 0.80241688]\n",
      "85\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_173057\n",
      "Epoch 00110: early stopping\n",
      "215/215 [==============================] - 0s 434us/step\n",
      "[0.         0.81154567 0.81154567 0.81154567 0.81154567 0.81154567\n",
      " 0.81154567 0.81154567 0.81154567 0.81154567 0.81154567 0.81154567\n",
      " 0.81154567]\n",
      "86\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_173108\n",
      "Epoch 00098: early stopping\n",
      "215/215 [==============================] - 0s 902us/step\n",
      "[0.         0.8397301  0.839792   0.839792   0.84003962 0.84003962\n",
      " 0.84003962 0.83991581 0.83991581 0.83985391 0.84003962 0.83985391\n",
      " 0.83991581]\n",
      "87\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_173121\n",
      "Epoch 00084: early stopping\n",
      "215/215 [==============================] - 0s 911us/step\n",
      "[0.         0.86733462 0.86745534 0.86745534 0.86733462 0.86733462\n",
      " 0.86733462 0.86733462 0.86733462 0.86733462 0.86733462 0.86733462\n",
      " 0.86733462]\n",
      "88\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_173131\n",
      "Epoch 00087: early stopping\n",
      "215/215 [==============================] - 0s 927us/step\n",
      "[0.         0.85826975 0.85826975 0.85826975 0.85826975 0.85826975\n",
      " 0.85826975 0.85826975 0.85826975 0.85826975 0.85826975 0.85839907\n",
      " 0.85833441]\n",
      "89\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_173142\n",
      "Epoch 00099: early stopping\n",
      "215/215 [==============================] - 0s 849us/step\n",
      "[0.         0.79872723 0.79872723 0.79872723 0.79872723 0.79872723\n",
      " 0.79872723 0.79872723 0.79872723 0.79872723 0.79872723 0.79872723\n",
      " 0.79872723]\n",
      "90\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_173153\n",
      "Epoch 00120: early stopping\n",
      "215/215 [==============================] - 0s 872us/step\n",
      "[0.         0.788194   0.78813019 0.78838545 0.78825782 0.78825782\n",
      " 0.78838545 0.78838545 0.78838545 0.78838545 0.78838545 0.78838545\n",
      " 0.78838545]\n",
      "91\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_173206\n",
      "Epoch 00093: early stopping\n",
      "215/215 [==============================] - 0s 757us/step\n",
      "[0.         0.8354414  0.83569954 0.83569954 0.83569954 0.8358286\n",
      " 0.8358286  0.8358286  0.8358286  0.8358286  0.8358286  0.8358286\n",
      " 0.8358286 ]\n",
      "92\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_173217\n",
      "Epoch 00101: early stopping\n",
      "215/215 [==============================] - 0s 616us/step\n",
      "[0.         0.80378965 0.80351504 0.80351504 0.80351504 0.80351504\n",
      " 0.80351504 0.80351504 0.80351504 0.80351504 0.80344638 0.80337773\n",
      " 0.80330908]\n",
      "93\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_173228\n",
      "Epoch 00095: early stopping\n",
      "215/215 [==============================] - 0s 648us/step\n",
      "[0.         0.82714431 0.82728994 0.82728994 0.82728994 0.82728994\n",
      " 0.82728994 0.82728994 0.82728994 0.82728994 0.82728994 0.82728994\n",
      " 0.82728994]\n",
      "94\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_173238\n",
      "Epoch 00071: early stopping\n",
      "215/215 [==============================] - 0s 538us/step\n",
      "[0.         0.82508054 0.82543849 0.82543849 0.82543849 0.82543849\n",
      " 0.82543849 0.82543849 0.82555781 0.82555781 0.82555781 0.82555781\n",
      " 0.82555781]\n",
      "95\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_173246\n",
      "Epoch 00101: early stopping\n",
      "215/215 [==============================] - 0s 867us/step\n",
      "[0.         0.77485953 0.77485953 0.77485953 0.7749902  0.7749902\n",
      " 0.7749902  0.7749902  0.7749902  0.7749902  0.7749902  0.7749902\n",
      " 0.7749902 ]\n",
      "96\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_173259\n",
      "Epoch 00113: early stopping\n",
      "215/215 [==============================] - 0s 908us/step\n",
      "[0.         0.83713927 0.8370138  0.8370138  0.8370138  0.8370138\n",
      " 0.8370138  0.8370138  0.8370138  0.8370138  0.8370138  0.8370138\n",
      " 0.8370138 ]\n",
      "97\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_173312\n",
      "Epoch 00119: early stopping\n",
      "215/215 [==============================] - 0s 925us/step\n",
      "[0.         0.84207596 0.84213782 0.84213782 0.84226154 0.84226154\n",
      " 0.84226154 0.84226154 0.84213782 0.84226154 0.84238525 0.8420141\n",
      " 0.84176667]\n",
      "98\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_173326\n",
      "Epoch 00088: early stopping\n",
      "215/215 [==============================] - 0s 912us/step\n",
      "[0.         0.86133194 0.86107129 0.86094096 0.86107129 0.86107129\n",
      " 0.86107129 0.86107129 0.86107129 0.86094096 0.86094096 0.86107129\n",
      " 0.86107129]\n",
      "99\n",
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0/log_DeepSurv_20191211_173336\n",
      "Epoch 00075: early stopping\n",
      "215/215 [==============================] - 0s 880us/step\n",
      "[0.         0.82833518 0.82882883 0.82882883 0.82895224 0.82895224\n",
      " 0.82895224 0.82895224 0.82895224 0.82895224 0.82895224 0.82895224\n",
      " 0.82895224]\n",
      "0.7461725494978144\n"
     ]
    }
   ],
   "source": [
    "import sys, os, datetime, h5py\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, model_from_json\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense,  Dropout, Activation, Concatenate, Lambda\n",
    "#from tensorflow.python.keras.summary import merge\n",
    "from tensorflow.keras.utils import plot_model, multi_gpu_model\n",
    "from tensorflow.keras.callbacks import CSVLogger, LearningRateScheduler, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import regularizers\n",
    "from functools import partial, update_wrapper\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "np.random.seed(np.random.randint(100000))\n",
    "\n",
    "datadir = \"/home/k1onoda/work/DeepSurvival_20191111\".replace('/', os.sep)\n",
    "\n",
    "isAAL = 0\n",
    "withAge = 0\n",
    "withMMSE = 0\n",
    "permutation = 0\n",
    "\n",
    "onlyMCI = 0;\n",
    "\n",
    "Itr = 100\n",
    "\n",
    "CVs = 10\n",
    "DROPOUT_RATIO = 0.3\n",
    "NB_EPOCH = 1000\n",
    "BATCH_SIZE = 128\n",
    "N_GPUS = 1\n",
    "#MRI = 2 # 1:1.5T 2: 3.0T\n",
    "\n",
    "if  isAAL == 0:\n",
    "    subdir_name = \"BN_Age\" +str(withAge)+\"_MMSE\"+str(withMMSE)\n",
    "else:\n",
    "    subdir_name = \"AAL_Age\"+str(withAge)+\"_MMSE\"+str(withMMSE)\n",
    "\n",
    "if permutation == 1:\n",
    "    subdir_name = subdir_name + \"_permutation\"\n",
    "if onlyMCI == 1:\n",
    "    subdir_name = subdir_name + \"_onlyMCI\"\n",
    "    \n",
    "subdir = datadir + os.sep + subdir_name\n",
    "os.makedirs(subdir, exist_ok = True)  \n",
    "\n",
    "J = 13\n",
    "FINAL1 = np.zeros([Itr,J])\n",
    "\n",
    "for ii in range(Itr):\n",
    "    \n",
    "    print(ii)\n",
    "    K.clear_session()\n",
    "    os.chdir( datadir )\n",
    "    data = io.loadmat(\"GMV_20191111.mat\")\n",
    "    gmv = np.array( data[\"GMV\"], dtype = 'float32' )\n",
    "    if isAAL == 1:\n",
    "        data = io.loadmat(\"GMV_AAL_20191111.mat\")\n",
    "        gmv = np.array( data[\"GMV\"], dtype = 'float32' )\n",
    "    nROIs = gmv.shape[1]    \n",
    "    \n",
    "    data = io.loadmat(\"Demo_20191111.mat\" )\n",
    "    demo = np.array( data[\"Demo\"], dtype = 'float32'  )   # database group mri subjectID age sex convert interval MMSE\n",
    "\n",
    "    #mristrength = np.array([demo[:,2]/2]).T\n",
    "    #gmv = np.concatenate([gmv,mristrength],axis=1) \n",
    "    if withAge==1:\n",
    "        age = np.array([demo[:,4]/100]).T\n",
    "        gmv = np.concatenate([gmv, age],axis=1)\n",
    "    if withMMSE==1:\n",
    "        mmse = np.array([demo[:,8]/30]).T\n",
    "        gmv = np.concatenate([gmv, mmse],axis=1)\n",
    "        gmv = np.delete(gmv, np.where(demo[:,8]==0), 0)\n",
    "        demo = np.delete(demo, np.where(demo[:,8]==0), 0)\n",
    "    \n",
    "    if onlyMCI==1:\n",
    "        gmv = np.delete(gmv, np.where(demo[:,1]==3), 0)\n",
    "        demo = np.delete(demo, np.where(demo[:,1]==3), 0)\n",
    "    \n",
    "    n_features = gmv.shape[1]   \n",
    "    nn = gmv.shape[0];\n",
    "    cv = np.zeros([nn])\n",
    "    \n",
    "    converter = (demo[:,6] == 1)  \n",
    "    n_converter = np.sum(converter)\n",
    "    sample_converter = np.arange(n_converter)\n",
    "    np.random.shuffle(sample_converter)\n",
    "    cv_converter = np.array(sample_converter % CVs)\n",
    "    cv[np.where(converter)] = cv_converter\n",
    "    \n",
    "    nonconverter = (demo[:,6] == 0)  \n",
    "    n_nonconverter = np.sum(nonconverter)\n",
    "    sample_nonconverter = np.arange(n_nonconverter)\n",
    "    np.random.shuffle(sample_nonconverter)\n",
    "    cv_nonconverter = np.array(sample_nonconverter % CVs)\n",
    "    cv[np.where(nonconverter)] = cv_nonconverter\n",
    "    \n",
    "    target_train = (cv>1)\n",
    "    target_vali = (cv==0)\n",
    "    target_test = (cv==1)\n",
    "\n",
    "    features_train = gmv[target_train,:]\n",
    "    features_vali = gmv[target_vali,:];\n",
    "    features_test = gmv[target_test,:];\n",
    "    \n",
    "    t = demo[:,7]\n",
    "    e = demo[:,6]\n",
    "    if  permutation == 1:\n",
    "        np.random.shuffle(t)\n",
    "        np.random.shuffle(e)\n",
    "\n",
    "    #J = np.int( np.round( np.max(t) ) + 1 )#J = np.int(np.ceil(np.max(t)) + 1)\n",
    "\n",
    "    T = np.round(t).astype('int64')#T = np.ceil(t).astype('int64')\n",
    "    T[T==0] = 1\n",
    "    E = np.zeros([nn,J])\n",
    "    mask = np.ones([nn,J]).astype('float32')\n",
    "    for num in range(nn):\n",
    "        if e[num] == 1:\n",
    "            E[num,T[num]:J] = 1\n",
    "        if e[num] == 0:\n",
    "            mask[num,T[num]+1:J] = 0\n",
    "    \n",
    "    E_train = E[target_train,:]\n",
    "    E_vali = E[target_vali,:]\n",
    "    E_test = E[target_test,:]\n",
    "    \n",
    "    T_test = T[target_test]\n",
    "    e_test = e[target_test]\n",
    "    \n",
    "    mask_train = mask[target_train,:]\n",
    "    mask_vali = mask[target_vali,:]\n",
    "    mask_test = mask[target_test,:]\n",
    "\n",
    "    todaydetail  =  datetime.datetime.today()\n",
    "    os.chdir(subdir)\n",
    "    logdir = subdir + os.sep + \"log_DeepSurv_\" + todaydetail.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    os.makedirs(logdir, exist_ok = True)\n",
    "    os.chdir(logdir)\n",
    "    print(os.getcwd())\n",
    "    experiment_name = 'deepsurv' \n",
    "\n",
    "    from tensorflow.python.client import device_lib\n",
    "    device_lib.list_local_devices()\n",
    "\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "\n",
    "        def output_of_lambda(input_shape):\n",
    "            shape = list(input_shape)\n",
    "            return (shape[0], J)\n",
    "\n",
    "        def weibull_cdf(parameters):\n",
    "            m = parameters[:,0]\n",
    "            s = tf.maximum( parameters[:,1], 0.001 )\n",
    "            output_list = []\n",
    "            for num in range( J ):\n",
    "                Time   = tf.constant( num, dtype=\"float32\")\n",
    "                e_Time = tf.pow( Time, m )\n",
    "                s_Time = tf.negative( tf.div( e_Time, s) )\n",
    "                x = tf.subtract( tf.constant(1, dtype=\"float32\") , tf.exp( s_Time ) ) # F(t) = 1 - exp(-(t-g)^m/s) #ref http://www.mogami.com/notes/weibull.html\n",
    "                output_list.append ( x )\n",
    "            return tf.stack(output_list, axis=1)\n",
    "\n",
    "        def generator_loss(y_true, y_pred, weights):  # y_true's shape=(batch_size, row, col, ch)\n",
    "            #loss = tf.cumsum( tf.multiply( tf.square( tf.subtract( y_pred, y_true ) ), weights ), axis=1, reverse=True)[:,0]\n",
    "            log_p = tf.log( tf.add( y_pred,  tf.constant(1.0) ) )\n",
    "            log_t = tf.log( tf.add( y_true,  tf.constant(1.0) ) )\n",
    "            loss = tf.cumsum( tf.multiply( tf.square( tf.subtract( log_p, log_t ) ), weights ), axis=1, reverse=True)[:,0]\n",
    "            return loss\n",
    "\n",
    "        def wrapped_generator_loss(func, *args, **kwargs):\n",
    "            partial_generator_loss = partial(generator_loss, *args, **kwargs)\n",
    "            update_wrapper(partial_generator_loss, generator_loss)\n",
    "            return partial_generator_loss\n",
    "\n",
    "        inputs = Input((n_features,), name='inputs')\n",
    "        x1 = Dense(units=32, activation='relu', name='hidden_layer1',\n",
    "                    kernel_regularizer=regularizers.l1_l2(0.001))(inputs)\n",
    "        x1 = Dropout(DROPOUT_RATIO)(x1)\n",
    "        x2 = Dense(units=32, activation='relu', name='hidden_layer2',\n",
    "                    kernel_regularizer=regularizers.l1_l2(0.001))(x1)\n",
    "        x2 = Dropout(DROPOUT_RATIO)(x2)\n",
    "        x3 = Dense(units=32, activation='relu', name='hidden_layer3',\n",
    "                    kernel_regularizer=regularizers.l1_l2(0.001))(x2)\n",
    "        x3 = Dropout(DROPOUT_RATIO)(x3)\n",
    "        p1 = Dense(units=1, activation='softplus', name='param1_layer')(x3)\n",
    "        p2 = Dense(units=1, activation='relu', name='param2_layer')(x3)\n",
    "        parameters = Concatenate(name='params_layer')([p1, p2])\n",
    "        y_pred = Lambda(weibull_cdf, output_shape=output_of_lambda)(parameters)\n",
    "\n",
    "        mask_batch = Input((J,), name='mask_bartch')\n",
    "        L = wrapped_generator_loss(generator_loss, weights = mask_batch)\n",
    "\n",
    "        model = Model(inputs= [inputs, mask_batch], outputs = y_pred)\n",
    "        #model.summary()\n",
    "    \n",
    "    if  N_GPUS>=2:\n",
    "        models = multi_gpu_model(model, gpus=N_GPUS)\n",
    "    else:\n",
    "        models = model\n",
    "\n",
    "    pred_params = np.zeros([nn,2])\n",
    "    c_index_test = np.zeros([J,1])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(features_train)\n",
    "    features_train = scaler.transform(features_train)\n",
    "    features_vali = scaler.transform(features_vali)\n",
    "    features_test = scaler.transform(features_test)\n",
    "\n",
    "    outputfilename     = 'Training.csv'\n",
    "    weightfilename     = 'WeightBest.h5'\n",
    "\n",
    "    checkpointer = ModelCheckpoint(filepath=weightfilename, monitor='loss', verbose=1, save_best_only=True)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss',patience=10,verbose=1)\n",
    "    callbacks = []\n",
    "    callbacks.append(early_stopping)\n",
    "    callbacks.append(CSVLogger(outputfilename))\n",
    "    #callbacks.append(checkpointer)\n",
    "\n",
    "    adm = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    models.compile(optimizer=adm, loss=L)\n",
    "    #models.compile(optimizer='Adam', loss='mean_squared_error', metrics=[\"accuracy\"])\n",
    "    session = K.get_session()\n",
    "\n",
    "    models.fit([features_train, mask_train], E_train, batch_size=BATCH_SIZE, epochs = NB_EPOCH, callbacks=callbacks, verbose=0, validation_data = ([features_vali, mask_vali], E_vali))\n",
    "    model.save_weights('Model_Weights_' + str(num+1) + '.h5')\n",
    "\n",
    "    #intermediate_model = Model(inputs=model.input, outputs=model.get_layer('params_layer').output)\n",
    "\n",
    "    #models.load_weights(weightfilename)\n",
    "    #models.compile(optimizer='Adam', loss=L)\n",
    "    prob = models.predict([features_test, mask_test], batch_size=BATCH_SIZE, verbose=1)\n",
    "    intermediate_model = Model(inputs=model.input, outputs=model.get_layer('params_layer').output)\n",
    "    pred_params = intermediate_model.predict([features_test, mask_test])\n",
    "\n",
    "    predictionfilename = 'Param.csv'\n",
    "    prediction = np.c_[demo[target_test,:],pred_params, prob]\n",
    "    np.savetxt(predictionfilename, prediction, delimiter=',')\n",
    "\n",
    "    c_index = np.zeros([J])\n",
    "    for num in range(J - 1) :\n",
    "        c_index[num+1] = concordance_index(np.array(T_test),1/prob[:,num+1], np.array(e_test))\n",
    "    print( c_index )\n",
    "\n",
    "    cindexfilename = 'C_index.txt'\n",
    "    np.savetxt(cindexfilename, c_index)\n",
    "    \n",
    "    FINAL1[ii,:] = c_index.T\n",
    "\n",
    "    #json_string = models.to_json()\n",
    "    #modeltxtfilename   = 'Modeltxt_' + 'Demo.txt'\n",
    "    #f = open(modeltxtfilename,'w')\n",
    "    #f.write(json_string)\n",
    "    #f.close()\n",
    "\n",
    "col_header1 = []\n",
    "for t in range(12):\n",
    "    col_header1.append(str(t+1) + 'yr c_index')\n",
    "    \n",
    "df_ci = pd.DataFrame(FINAL1[:,1:J], columns=col_header1)\n",
    "df_ci.to_csv(subdir + '/result_CINDEX.csv')\n",
    "print(np.mean(np.mean(FINAL1,axis=1),axis=0))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             (None, 246)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer1 (Dense)           (None, 32)           7904        inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32)           0           hidden_layer1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer2 (Dense)           (None, 32)           1056        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32)           0           hidden_layer2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer3 (Dense)           (None, 32)           1056        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32)           0           hidden_layer3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "param1_layer (Dense)            (None, 1)            33          dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "param2_layer (Dense)            (None, 1)            33          dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "params_layer (Concatenate)      (None, 2)            0           param1_layer[0][0]               \n",
      "                                                                 param2_layer[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 12)           0           params_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 10,082\n",
      "Trainable params: 10,082\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "'''\n",
    "\n",
    "import tensorflow as tf\n",
    "from functools import partial, update_wrapper\n",
    "from keras.layers import Input,InputLayer, Dense, Dropout, Activation, Concatenate, Lambda \n",
    "from keras.models import Model, model_from_json\n",
    "from keras import regularizers\n",
    "from scipy import io\n",
    "\n",
    "J = 12\n",
    "DROPOUT_RATIO = 0.5\n",
    "\n",
    "def output_of_lambda(input_shape):\n",
    "    shape = list(input_shape)\n",
    "    return (shape[0], J)\n",
    "\n",
    "def weibull_cdf(parameters):\n",
    "    m = parameters[:,0]\n",
    "    s = tf.maximum( parameters[:,1], 0.001 )\n",
    "    output_list = []\n",
    "    for ii in range( J ):\n",
    "        Time   = tf.constant( ii, dtype=\"float32\")\n",
    "        e_Time = tf.pow( Time, m )\n",
    "        s_Time = tf.negative( tf.div( e_Time, s) )\n",
    "        x = tf.subtract( tf.constant(1, dtype=\"float32\") , tf.exp( s_Time ) ) # F(t) = 1 - exp(-(t-g)^m/s) #ref http://www.mogami.com/notes/weibull.html\n",
    "        output_list.append ( x )\n",
    "    return tf.stack(output_list, axis=1)\n",
    "\n",
    "def generator_loss(y_true, y_pred, weights):  # y_true's shape=(batch_size, row, col, ch)\n",
    "    #loss = tf.cumsum( tf.multiply( tf.square( tf.subtract( y_pred, y_true ) ), weights ), axis=1, reverse=True)[:,0]\n",
    "    log_p = tf.log( tf.add( y_pred,  tf.constant(1.0) ) )\n",
    "    log_t = tf.log( tf.add( y_true,  tf.constant(1.0) ) )\n",
    "    loss = tf.cumsum( tf.multiply( tf.square( tf.subtract( log_p, log_t ) ), weights ), axis=1, reverse=True)[:,0]\n",
    "    return loss\n",
    "\n",
    "def wrapped_generator_loss(func, *args, **kwargs):\n",
    "    partial_generator_loss = partial(generator_loss, *args, **kwargs)\n",
    "    update_wrapper(partial_generator_loss, generator_loss)\n",
    "    return partial_generator_loss\n",
    "\n",
    "inputs = Input((246,), name='inputs')\n",
    "x1 = Dense(units=32, activation='relu', name='hidden_layer1', kernel_regularizer=regularizers.l1_l2(0.001))(inputs)\n",
    "x1 = Dropout(DROPOUT_RATIO)(x1)\n",
    "x2 = Dense(units=32, activation='relu', name='hidden_layer2', kernel_regularizer=regularizers.l1_l2(0.001))(x1)\n",
    "x2 = Dropout(DROPOUT_RATIO)(x2)\n",
    "x3 = Dense(units=32, activation='relu', name='hidden_layer3', kernel_regularizer=regularizers.l1_l2(0.001))(x2)\n",
    "x3 = Dropout(DROPOUT_RATIO)(x3)\n",
    "p1 = Dense(units=1, activation='softplus', name='param1_layer')(x3)\n",
    "p2 = Dense(units=1, activation='relu', name='param2_layer')(x3)\n",
    "parameters = Concatenate(name='params_layer')([p1, p2])\n",
    "y_pred = Lambda(weibull_cdf, output_shape=output_of_lambda)(parameters)\n",
    "\n",
    "mask_batch = Input((J,), name='mask_bartch')\n",
    "L = wrapped_generator_loss(generator_loss, weights=mask_batch)\n",
    "\n",
    "model = Model(inputs= [inputs, mask_batch], outputs = y_pred)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0_taylar\n",
      "<class 'list'>\n",
      "log_DeepSurv_20191203_173519/Model_Weights_2142.h5\n",
      "1\n",
      "log_DeepSurv_20191203_173642/Model_Weights_2142.h5\n",
      "2\n",
      "log_DeepSurv_20191203_173931/Model_Weights_2142.h5\n",
      "3\n",
      "log_DeepSurv_20191203_173407/Model_Weights_2142.h5\n",
      "4\n",
      "log_DeepSurv_20191203_172908/Model_Weights_2142.h5\n",
      "5\n",
      "log_DeepSurv_20191203_173656/Model_Weights_2142.h5\n",
      "6\n",
      "log_DeepSurv_20191203_173610/Model_Weights_2142.h5\n",
      "7\n",
      "log_DeepSurv_20191203_173205/Model_Weights_2142.h5\n",
      "8\n",
      "log_DeepSurv_20191203_172857/Model_Weights_2142.h5\n",
      "9\n",
      "log_DeepSurv_20191203_174328/Model_Weights_2142.h5\n",
      "10\n",
      "log_DeepSurv_20191203_173959/Model_Weights_2142.h5\n",
      "11\n",
      "log_DeepSurv_20191203_174527/Model_Weights_2142.h5\n",
      "12\n",
      "log_DeepSurv_20191203_173812/Model_Weights_2142.h5\n",
      "13\n",
      "log_DeepSurv_20191203_173730/Model_Weights_2142.h5\n",
      "14\n",
      "log_DeepSurv_20191203_173256/Model_Weights_2142.h5\n",
      "15\n",
      "log_DeepSurv_20191203_173033/Model_Weights_2142.h5\n",
      "16\n",
      "log_DeepSurv_20191203_174234/Model_Weights_2142.h5\n",
      "17\n",
      "log_DeepSurv_20191203_174225/Model_Weights_2142.h5\n",
      "18\n",
      "log_DeepSurv_20191203_172940/Model_Weights_2142.h5\n",
      "19\n",
      "log_DeepSurv_20191203_173344/Model_Weights_2142.h5\n",
      "20\n",
      "log_DeepSurv_20191203_173550/Model_Weights_2142.h5\n",
      "21\n",
      "log_DeepSurv_20191203_172920/Model_Weights_2142.h5\n",
      "22\n",
      "log_DeepSurv_20191203_173528/Model_Weights_2142.h5\n",
      "23\n",
      "log_DeepSurv_20191203_173321/Model_Weights_2142.h5\n",
      "24\n",
      "log_DeepSurv_20191203_173920/Model_Weights_2142.h5\n",
      "25\n",
      "log_DeepSurv_20191203_172839/Model_Weights_2142.h5\n",
      "26\n",
      "log_DeepSurv_20191203_173056/Model_Weights_2142.h5\n",
      "27\n",
      "log_DeepSurv_20191203_173045/Model_Weights_2142.h5\n",
      "28\n",
      "log_DeepSurv_20191203_172847/Model_Weights_2142.h5\n",
      "29\n",
      "log_DeepSurv_20191203_174129/Model_Weights_2142.h5\n",
      "30\n",
      "log_DeepSurv_20191203_173743/Model_Weights_2142.h5\n",
      "31\n",
      "log_DeepSurv_20191203_173014/Model_Weights_2142.h5\n",
      "32\n",
      "log_DeepSurv_20191203_173218/Model_Weights_2142.h5\n",
      "33\n",
      "log_DeepSurv_20191203_173420/Model_Weights_2142.h5\n",
      "34\n",
      "log_DeepSurv_20191203_173356/Model_Weights_2142.h5\n",
      "35\n",
      "log_DeepSurv_20191203_174446/Model_Weights_2142.h5\n",
      "36\n",
      "log_DeepSurv_20191203_174611/Model_Weights_2142.h5\n",
      "37\n",
      "log_DeepSurv_20191203_174412/Model_Weights_2142.h5\n",
      "38\n",
      "log_DeepSurv_20191203_173632/Model_Weights_2142.h5\n",
      "39\n",
      "log_DeepSurv_20191203_174119/Model_Weights_2142.h5\n",
      "40\n",
      "log_DeepSurv_20191203_174152/Model_Weights_2142.h5\n",
      "41\n",
      "log_DeepSurv_20191203_173142/Model_Weights_2142.h5\n",
      "42\n",
      "log_DeepSurv_20191203_173433/Model_Weights_2142.h5\n",
      "43\n",
      "log_DeepSurv_20191203_173708/Model_Weights_2142.h5\n",
      "44\n",
      "log_DeepSurv_20191203_174401/Model_Weights_2142.h5\n",
      "45\n",
      "log_DeepSurv_20191203_173308/Model_Weights_2142.h5\n",
      "46\n",
      "log_DeepSurv_20191203_173836/Model_Weights_2142.h5\n",
      "47\n",
      "log_DeepSurv_20191203_173910/Model_Weights_2142.h5\n",
      "48\n",
      "log_DeepSurv_20191203_173752/Model_Weights_2142.h5\n",
      "49\n",
      "log_DeepSurv_20191203_174045/Model_Weights_2142.h5\n",
      "50\n",
      "log_DeepSurv_20191203_173107/Model_Weights_2142.h5\n",
      "51\n",
      "log_DeepSurv_20191203_174538/Model_Weights_2142.h5\n",
      "52\n",
      "log_DeepSurv_20191203_174204/Model_Weights_2142.h5\n",
      "53\n",
      "log_DeepSurv_20191203_173245/Model_Weights_2142.h5\n",
      "54\n",
      "log_DeepSurv_20191203_174215/Model_Weights_2142.h5\n",
      "55\n",
      "log_DeepSurv_20191203_172929/Model_Weights_2142.h5\n",
      "56\n",
      "log_DeepSurv_20191203_174548/Model_Weights_2142.h5\n",
      "57\n",
      "log_DeepSurv_20191203_174600/Model_Weights_2142.h5\n",
      "58\n",
      "log_DeepSurv_20191203_173154/Model_Weights_2142.h5\n",
      "59\n",
      "log_DeepSurv_20191203_174318/Model_Weights_2142.h5\n",
      "60\n",
      "log_DeepSurv_20191203_173802/Model_Weights_2142.h5\n",
      "61\n",
      "log_DeepSurv_20191203_174518/Model_Weights_2142.h5\n",
      "62\n",
      "log_DeepSurv_20191203_174055/Model_Weights_2142.h5\n",
      "63\n",
      "log_DeepSurv_20191203_172814/Model_Weights_2142.h5\n",
      "64\n",
      "log_DeepSurv_20191203_174106/Model_Weights_2142.h5\n",
      "65\n",
      "log_DeepSurv_20191203_174308/Model_Weights_2142.h5\n",
      "66\n",
      "log_DeepSurv_20191203_174633/Model_Weights_2142.h5\n",
      "67\n",
      "log_DeepSurv_20191203_174623/Model_Weights_2142.h5\n",
      "68\n",
      "log_DeepSurv_20191203_173231/Model_Weights_2142.h5\n",
      "69\n",
      "log_DeepSurv_20191203_173119/Model_Weights_2142.h5\n",
      "70\n",
      "log_DeepSurv_20191203_173939/Model_Weights_2142.h5\n",
      "71\n",
      "log_DeepSurv_20191203_174035/Model_Weights_2142.h5\n",
      "72\n",
      "log_DeepSurv_20191203_173858/Model_Weights_2142.h5\n",
      "73\n",
      "log_DeepSurv_20191203_173847/Model_Weights_2142.h5\n",
      "74\n",
      "log_DeepSurv_20191203_174350/Model_Weights_2142.h5\n",
      "75\n",
      "log_DeepSurv_20191203_174435/Model_Weights_2142.h5\n",
      "76\n",
      "log_DeepSurv_20191203_173333/Model_Weights_2142.h5\n",
      "77\n",
      "log_DeepSurv_20191203_173001/Model_Weights_2142.h5\n",
      "78\n",
      "log_DeepSurv_20191203_174012/Model_Weights_2142.h5\n",
      "79\n",
      "log_DeepSurv_20191203_174243/Model_Weights_2142.h5\n",
      "80\n",
      "log_DeepSurv_20191203_174340/Model_Weights_2142.h5\n",
      "81\n",
      "log_DeepSurv_20191203_173456/Model_Weights_2142.h5\n",
      "82\n",
      "log_DeepSurv_20191203_173622/Model_Weights_2142.h5\n",
      "83\n",
      "log_DeepSurv_20191203_173507/Model_Weights_2142.h5\n",
      "84\n",
      "log_DeepSurv_20191203_174421/Model_Weights_2142.h5\n",
      "85\n",
      "log_DeepSurv_20191203_174022/Model_Weights_2142.h5\n",
      "86\n",
      "log_DeepSurv_20191203_173949/Model_Weights_2142.h5\n",
      "87\n",
      "log_DeepSurv_20191203_173601/Model_Weights_2142.h5\n",
      "88\n",
      "log_DeepSurv_20191203_172826/Model_Weights_2142.h5\n",
      "89\n",
      "log_DeepSurv_20191203_173445/Model_Weights_2142.h5\n",
      "90\n",
      "log_DeepSurv_20191203_174508/Model_Weights_2142.h5\n",
      "91\n",
      "log_DeepSurv_20191203_173540/Model_Weights_2142.h5\n",
      "92\n",
      "log_DeepSurv_20191203_173024/Model_Weights_2142.h5\n",
      "93\n",
      "log_DeepSurv_20191203_172950/Model_Weights_2142.h5\n",
      "94\n",
      "log_DeepSurv_20191203_174140/Model_Weights_2142.h5\n",
      "95\n",
      "log_DeepSurv_20191203_173130/Model_Weights_2142.h5\n",
      "96\n",
      "log_DeepSurv_20191203_173718/Model_Weights_2142.h5\n",
      "97\n",
      "log_DeepSurv_20191203_174253/Model_Weights_2142.h5\n",
      "98\n",
      "log_DeepSurv_20191203_173823/Model_Weights_2142.h5\n",
      "99\n",
      "log_DeepSurv_20191203_174457/Model_Weights_2142.h5\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "import os, scipy, glob, innvestigate\n",
    "import numpy as np\n",
    "\n",
    "permutation = 0\n",
    "DROPOUT_RATIO = 0.5\n",
    "\n",
    "data = io.loadmat(\"/home/k1onoda/work/DeepSurvival_20191111/GMV_20191111.mat\".replace('/', os.sep))\n",
    "gmv = np.array( data[\"GMV\"], dtype = 'float32' )\n",
    "\n",
    "datadir = \"/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0_taylar\".replace('/', os.sep)\n",
    "if permutation == 1:\n",
    "    datadir = \"/home/k1onoda/work/DeepSurvival_20191111/BN_Age0_MMSE0_permutation\".replace('/', os.sep)\n",
    "    \n",
    "os.chdir( datadir )\n",
    "print(os.getcwd())\n",
    "    \n",
    "h5files = glob.glob('**/**.h5', recursive=True)\n",
    "print(type(h5files))\n",
    "\n",
    "data = np.zeros([100,246])\n",
    "n = 0\n",
    "for file in h5files:\n",
    "    print(file)\n",
    "    model.load_weights(file)\n",
    "    intermediate_model = Model(inputs=model.get_layer('inputs').input, outputs=model.get_layer('param1_layer').output)\n",
    "\n",
    "    analyzer = innvestigate.create_analyzer(\"deep_taylor\", intermediate_model)\n",
    "    data[n,:] = np.mean(analyzer.analyze(gmv),axis=0)\n",
    "    n = n + 1\n",
    "    print(n)\n",
    "    \n",
    "os.chdir( datadir )\n",
    "dt_filename = 'deep_taylor.mat'\n",
    "scipy.io.savemat(dt_filename, {'deep_taylor':data})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 246)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
